# @package _global_
defaults:
  - /experiment/wt103/base.yaml

model_name: hyena-125
model:
  _name_: lm
  d_model: 768
  d_inner: 3072
  n_layer: 12
  vocab_size: 50257
  embed_dropout: 0.1
  layer:
    _name_: hyena
    emb_dim: 33
    filter_order: 64
    local_order: 3
    l_max: 1024
    modulate: False
    w: 14
  fused_mlp: True
  fused_dropout_add_ln: True
  residual_in_fp32: True
  pad_vocab_size_multiple: 8
